<!doctype html> <html lang=en > <meta charset=utf-8 > <meta name=viewport  content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv=x-ua-compatible  content="ie=edge"> <meta name=author  content="Julia 中文社区的全体成员"> <meta name=description  content="Julia 中文社区的主页。Julia 中文社区是一个社区驱动、致力于 Julia 编程语言中文支持的开源组织。"> <meta name=keywords  content="Julia 中文, Julia 语言, Julia 中文社区, Julia 编程语言"> <meta name=robots  content="index, follow"> <meta property="og:title" content="Julia 中文社区"> <meta property="og:image" content="/assets/infra/logo_cn.png"> <meta property="og:description" content="社区驱动，致力于 Julia 编程语言中文支持的开源组织"> <link rel=stylesheet  href="/libs/bootstrap/bootstrap.min.css"> <link rel=stylesheet  href="/css/app.css"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/fonts.css"> <link href="https://fonts.googleapis.com/css?family=Roboto:400,400i,500,500i,700,700i" rel=stylesheet > <link href="https://libs.cdnjs.net/font-awesome/4.7.0/css/font-awesome.min.css" rel=stylesheet > <script async defer src="/libs/buttons.js"></script> <!-- --> <script type="application/javascript"> var doNotTrack = false; if (!doNotTrack) { window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date; ga('create', 'UA-28835595-9', 'auto'); ga('send', 'pageview'); } </script> <script async src='https://www.google-analytics.com/analytics.js'></script> <link rel=icon  href="/assets/infra/julia.ico"> <link rel=stylesheet  href="/libs/highlight/github.min.css"> <title>Beyond machine learning pipelines with MLJ</title> <style> .container ul li p {margin-bottom: 0;} </style> <style> .main { font-family: Georgia; } .main pre { margin-left: auto; margin-right: auto; } .main { width: 100%; font-size: 100%; } .main code { font-size: 90%; } .main pre code { font-size: 90%; } @media (min-width: 940px) { .main { width: 800px; } .container.blog-title { width: 800px;} } </style> <div class="container py-3 py-lg-0"> <nav class="navbar navbar-expand-lg navbar-light bg-light" id=main-menu > <a class=navbar-brand  href="/"> <img src="/assets/infra/logo_cn.png" alt="JuliaLang Logo"> </a> <button class="navbar-toggler ml-auto hidden-sm-up float-xs-left" type=button  data-toggle=collapse  data-target="#navbarSupportedContent" aria-controls=navbarSupportedContent  aria-expanded=false  aria-label="Toggle navigation"> <span class=navbar-toggler-icon ></span> </button> <div class="collapse navbar-collapse" id=navbarSupportedContent > <ul class="navbar-nav mx-auto"> <li class="nav-item flex-md-fill text-md-center"> <a class=nav-link  href="/downloads/">下载</a> <li class="nav-item flex-md-fill text-md-center"> <a class=nav-link  href="https://docs.juliacn.com/">文档</a> <li class="nav-item active flex-md-fill text-md-center"> <a class=nav-link  href="https://julialang.org/blog/">博客</a> <li class="nav-item flex-md-fill text-md-center"> <a class=nav-link  href="https://discourse.juliacn.com/">社区</a> <li class="nav-item flex-md-fill text-md-center"> <a class=nav-link  href="https://learn.juliacn.com/docs/meta/how_to_learn.html">学习</a> <li class="nav-item flex-md-fill text-md-center"> <a class=nav-link  href="https://julialang.org/research/">研究</a> <li class="nav-item flex-md-fill text-md-center"> <a class=nav-link  href="https://julialang.org/jsoc/">JSoC</a> </ul> <span class=navbar-right > <a class=github-button  href="https://github.com/sponsors/julialang" data-icon=octicon-heart  data-size=large  aria-label="Sponsor @julialang on GitHub">赞助 JuliaLang 组织</a> </span> </div> </nav> </div> <br><br> <div class="container blog-title"> <h1>Beyond machine learning pipelines with MLJ <a type="application/rss+xml" href="https://julialang.org/feed.xml"> <i class="fa fa-rss-square rss-icon"></i> </a> </h1> <h3> <span style="font-weight: lighter;"> 2 May 2019 </span> | <span style="font-weight: bold;"></span> <span style="font-weight: bold;">Anthony Blaom, Diego Arenas, Franz Kiraly, Yiannis Simillides, Sebastian Vollmer </span> </h3> </div> <a href="https://github.com/JuliaLang/www.julialang.org/blob/master/blog/2019/05/beyond-ml-pipelines-with-mlj.md" title="Edit this page on GitHub" class=edit-float > </a> <div class="container main"> <p float=left  align=middle > <img style="width:40%;padding:0;" src="/assets/blog/2019-05-02-MLJ/learningcurves.png"/> <img style="width:40%;padding-left:15px;" src="/assets/blog/2019-05-02-MLJ/heatmap.png"/> </p> <p float=left  align=middle > <img style="width:40%;padding:0;" src="/assets/blog/2019-05-02-MLJ/wrapped_ridge.png"/> <img style="width:40%;padding-left:15px;" src="/assets/blog/2019-05-02-MLJ/MLPackages.png"/> </p> <div class=franklin-toc ><ol><li><a href="#introduction">Introduction</a><li><a href="#mlj_features">MLJ features</a><li><a href="#learning_networks">Learning networks</a><li><a href="#building_a_simple_network">Building a simple network</a><li><a href="#exporting_and_retraining">Exporting and retraining</a><li><a href="#just_write_the_math">Just &quot;Write the math&#33;&quot;</a><li><a href="#invitation_to_the_community">Invitation to the community</a></ol></div> <h2 id=introduction ><a href="#introduction" class=header-anchor >Introduction</a></h2> <p><a href="https://github.com/alan-turing-institute/MLJ.jl">MLJ</a> is an open-source machine learning toolbox written in pure Julia. It provides a uniform interface for interacting with supervised and unsupervised learning models currently scattered in different Julia packages.</p> <p>Building on a earlier proof-of-concept, development began in earnest at <a href="https://www.turing.ac.uk">The Alan Turing Institute</a> in December 2018. In a short time interest grew and the project is now the Institute&#39;s most starred software repository.</p> <p>After outlining MLJ&#39;s current functionality, this post introduces MLJ <strong>learning networks</strong>, a super-charged pipelining feature for model composition.</p> <p><strong>Quick links:</strong></p> <p>&#9758; <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/frequently_asked_questions/">MLJ vs ScikitLearn.jl</a></p> <p>&#9758; Video from <a href="https://www.youtube.com/watch?v&#61;CfHkjNmj1eE">London Julia User Group meetup in March 2019</a> &#40;skip to <a href="https://youtu.be/CfHkjNmj1eE?t&#61;21m39s">demo at 21&#39;39</a>&#41; &nbsp;</p> <iframe width=560  height=315  src="https://www.youtube.com/embed/CfHkjNmj1eE?start=1300" frameborder=0  allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> <p>&#9758; The MLJ <a href="https://alan-turing-institute.github.io/MLJTutorials/">tutorials</a>.</p> <p>&#9758; Building a <a href="https://alan-turing-institute.github.io/MLJTutorials/getting-started/model-tuning/">self-tuning random forest</a></p> <p>&#9758; An MLJ <a href="https://github.com/ysimillides/mlj-docker">docker image</a> &#40;including tour&#41;</p> <p>&#9758; Implementing the MLJ interface for a <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/adding_models_for_general_use/">new model</a></p> <p>&#9758; How to <a href="https://github.com/alan-turing-institute/MLJ.jl/blob/master/CONTRIBUTING.md">contribute</a></p> <p>&#9758; Julia <a href="https://julialang.slack.com">Slack</a> channel: #mlj.</p> <p>&#9758; Star&#39;ing us to show support for <a href="https://github.com/alan-turing-institute/MLJ.jl">MLJ</a> would be greatly appreciated&#33;</p> <h2 id=mlj_features ><a href="#mlj_features" class=header-anchor >MLJ features</a></h2> <p>MLJ already has substantial functionality:</p> <ul> <li><p><strong>Learning networks.</strong> Flexible model composition beyond traditional pipelines &#40;more on this below&#41;.</p> <li><p><strong>Automatic tuning.</strong> Automated tuning of hyperparameters, including composite models. Tuning implemented as a model wrapper for composition with other meta-algorithms.</p> <li><p><strong>Homogeneous model ensembling.</strong></p> <li><p><strong>Registry for model metadata.</strong> Metadata available without loading model code. Basis of a &quot;task&quot; interface and facilitates model composition.</p> <li><p><strong>Task interface.</strong> Automatically match models to specified learning tasks, to streamline benchmarking and model selection.</p> <li><p><strong>Clean probabilistic API.</strong> Improves support for Bayesian statistics and probabilistic graphical models.</p> <li><p><strong>Data container agnostic.</strong> Present and manipulate data in your favorite Tables.jl format.</p> <li><p><strong>Universal adoption of categorical data types.</strong> Enables model implementations to properly account for classes seen in training but not in evaluation.</p> </ul> <p>Enhancements planned for the near future include integration of Flux.jl <strong>deep learning</strong> models, and <strong>gradient descent tuning</strong> of continuous hyperparameters using automatic differentiation.</p> <p>While a relatively small number of machine learning models currently implement the MLJ interface, work in progress aims to wrap models supported by the popular python framework, scikit-learn, as a temporary expedient. For a comparison of the MLJ&#39;s design with the Julia wrap <a href="https://github.com/cstjean/ScikitLearn.jl">ScikitLearn.jl</a>, see this <a href="https://github.com/alan-turing-institute/MLJ.jl/blob/master/docs/src/frequently_asked_questions.md">FAQ</a>.</p> <h2 id=learning_networks ><a href="#learning_networks" class=header-anchor >Learning networks</a></h2> <p>MLJ&#39;s model composition interface is flexible enough to implement, for example, the <a href="https://www.kdnuggets.com/2017/02/stacking-models-imropved-predictions.html">model stacks</a> popular in data science competitions. To treat examples of this kind, the interface design must account for the fact that information flow in prediction and training modes is different. This can be seen from the following schematic of a simple two-model stack, viewed as a network:</p> <p><img src="/assets/blog/2019-05-02-MLJ/two_model_stack.png" alt="" /></p> <h2 id=building_a_simple_network ><a href="#building_a_simple_network" class=header-anchor >Building a simple network</a></h2> <p>In MLJ, networks of models are built using a declarative syntax already familiar from basic use of the package. For example, the ordinary syntax for training a decision tree in MLJ, after one-hot encoding the categorical features, looks like this:</p> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> MLJ
<span class=hljs-meta >@load</span> DecisionTreeRegressor

<span class=hljs-comment ># load some data:</span>
task = load_reduced_ames();
X, y = task();

<span class=hljs-comment ># one-hot encode the inputs, X:</span>
hot_model = OneHotEncoder()
hot = machine(hot_model, X)
fit!(hot)
Xt = transform(hot, X)

<span class=hljs-comment ># fit a decision tree to the transformed data:</span>
tree_model = DecisionTreeRegressor()
tree = machine(tree_model, Xt, y)
fit!(tree, rows = <span class=hljs-number >1</span>:<span class=hljs-number >1300</span>)</code></pre> <p>Note that a <em>model</em> in MLJ is just a struct containing hyperparameters. Wrapping a model in data delivers a <em>machine</em> struct, which will additionally record the results of training.</p> <p>Without a pipeline, each time we want to present new data for prediction we must first apply one-hot encoding:</p> <pre><code class="julia hljs">Xnew = X[<span class=hljs-number >1301</span>:<span class=hljs-number >1400</span>,:];
Xnewt = transform(hot, Xnew);
yhat = predict(tree, Xnewt);
yhat[<span class=hljs-number >1</span>:<span class=hljs-number >3</span>]
 <span class=hljs-number >3</span>-element <span class=hljs-built_in >Array</span>{<span class=hljs-built_in >Float64</span>,<span class=hljs-number >1</span>}:
  <span class=hljs-number >223956.9999999999</span>
  <span class=hljs-number >320142.85714285733</span>
  <span class=hljs-number >161227.49999999994</span></code></pre> <p>To build a pipeline one simply wraps the supplied data in source nodes and repeats similar declarations, omitting calls to <code>fit&#33;</code>. The difference now is that each &quot;variable&quot; &#40;e.g., <code>Xt</code>, <code>yhat</code>&#41; is a node of our pipeline, instead of concrete data:</p> <pre><code class="julia hljs">Xs = source(X)
ys = source(y)

hot = machine(hot_model, Xs)
Xt = transform(hot, Xs);

tree = machine(tree_model, Xt, ys)
yhat = predict(tree, Xt)</code></pre> <p>If we like, we can think of a node as <em>dynamic data</em> - &quot;data&quot; because it can be called &#40;indexed&#41; on rows, but &quot;dynamic&quot; because the result depends on the outcome of training events, which in turn depend on hyperparameter values. For example, after fitting the completed pipeline, we can make new predictions like this:</p> <pre><code class="julia hljs">fit!(yhat, rows=<span class=hljs-number >1</span>:<span class=hljs-number >1300</span>)
 [ Info: Training NodalMachine @ <span class=hljs-number >1</span>…<span class=hljs-number >51.</span>
 [ Info: Spawned <span class=hljs-number >1300</span> sub-features to one-hot encode feature :Neighborhood.
 [ Info: Spawned <span class=hljs-number >1300</span> sub-features to one-hot encode feature :MSSubClass.
 [ Info: Training NodalMachine @ <span class=hljs-number >1</span>…<span class=hljs-number >17.</span>
 Node @ <span class=hljs-number >1</span>…<span class=hljs-number >79</span> = predict(<span class=hljs-number >1</span>…<span class=hljs-number >17</span>, transform(<span class=hljs-number >1</span>…<span class=hljs-number >51</span>, <span class=hljs-number >1</span>…<span class=hljs-number >07</span>))

yhat(rows=<span class=hljs-number >1301</span>:<span class=hljs-number >1302</span>) <span class=hljs-comment ># to predict on rows of source node</span>
yhat(Xnew)           <span class=hljs-comment ># to predict on new data</span>
<span class=hljs-number >156</span>-element <span class=hljs-built_in >Array</span>{<span class=hljs-built_in >Float64</span>,<span class=hljs-number >1</span>}:
 <span class=hljs-number >223956.9999999999</span>
 <span class=hljs-number >320142.85714285733</span>
 ...</code></pre> <h2 id=exporting_and_retraining ><a href="#exporting_and_retraining" class=header-anchor >Exporting and retraining</a></h2> <p>Once a pipeline like this has been built and tested on sample data, it can be exported as a stand-alone model, ready to be trained on any dataset. For details, see the MLJ <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/composing_models/#Learning-Networks-1">documentation</a>. In the future, Julia macros will allow common architectures &#40;e.g., linear pipelines&#41; to be built in a couple of lines.</p> <p>Finally, we mention that MLJ learning networks, and their exported counterparts, are &quot;smart&quot; in the sense that changing a hyperparameter does not trigger retraining of component models upstream of the change:</p> <pre><code class="julia hljs">tree_model.max_depth = <span class=hljs-number >4</span>
fit!(yhat, rows=<span class=hljs-number >1</span>:<span class=hljs-number >1300</span>)
 [ Info: Not retraining NodalMachine @ <span class=hljs-number >1</span>…<span class=hljs-number >51.</span> It is up-to-date.
 [ Info: Updating NodalMachine @ <span class=hljs-number >1</span>…<span class=hljs-number >17.</span>
 Node @ <span class=hljs-number >1</span>…<span class=hljs-number >79</span> = predict(<span class=hljs-number >1</span>…<span class=hljs-number >17</span>, transform(<span class=hljs-number >1</span>…<span class=hljs-number >51</span>, <span class=hljs-number >1</span>…<span class=hljs-number >07</span>))</code></pre> <h2 id=just_write_the_math ><a href="#just_write_the_math" class=header-anchor >Just &quot;Write the math&#33;&quot;</a></h2> <p>Because of Julia&#39;s generic programming features, any kind of operation you would normally apply to data &#40;arithmetic, row selection, column concatenation, etc&#41; can be overloaded to work with nodes. In this way, MLJ&#39;s network-building syntax is economical, intuitive and easy to read. In this respect we have been inspired by <a href="/blog/2017/12/ml-pl/">On Machine Learning and Programming Languages</a>.</p> <h2 id=invitation_to_the_community ><a href="#invitation_to_the_community" class=header-anchor >Invitation to the community</a></h2> <p>We now invite the community to try out our newly registered <a href="https://github.com/alan-turing-institute/MLJ.jl">MLJ</a> package and provide any feedback or suggestions you may have going forward. We are also particularly interested in hearing how you would use our package, and what features it may be lacking.</p> </div><br><br> <footer class="container-fluid footer-copy"> <div class=container > <div class="row footrow"> <ul> <li><a href="/project">关于我们</a> <li><a href="/about/help">寻求帮助</a> <li><a href="https://julialang.org/community/organizations/">特定领域的 Github 组织</a> <li><a href="/blog/2019/02/julia-entities/">管理者</a> <li><a href="/research/#publications">出版物</a> <li><a href="/research/#sponsors">Julia 语言赞助者</a> <li><a href="/research/#juliacn_sponsors">Julia 中文社区赞助者</a> </ul> <ul> <li><a href="/downloads/">下载</a> <li><a href="/downloads/">所有版本</a> <li><a href="https://github.com/JuliaLang/julia">源代码</a> <li><a href="/downloads/#current_stable_release">最新稳定版（Stable）</a> <li><a href="/downloads/#long_term_support_release">长期支持版本（LTS）</a> <li><a href="/downloads/platform/#platform_specific_instructions_for_unofficial_binaries">非官方编译版本</a> </ul> <ul> <li><a href="https://docs.juliacn.com/latest/">文档</a> <li><a href="https://docs.julialang.org/en/v1/">英文文档</a> <li><a href="/learning/getting-started/">初学者指南</a> <li><a href="https://docs.juliacn.com/latest/manual/faq/">常见问题（FAQ）</a> <li><a href="/learning/#books">书籍</a> </ul> <ul> <li><a href="/community/">社区</a> <li><a href="/community/#2019_julia_user_and_developer_survey">用户/开发者调查</a> <li><a href="/diversity/">多元化</a> <li><a href="/community/#official_channels">官方频道</a> <li><a href="/community/standards/">行为准则（CoC）</a> <li><a href="/community/#events">活动</a> <li><a href="https://shop.spreadshirt.com/numfocus/official+julia+logo?idea=5bca3ad9f93764414a5de55f">周边商店（SpreadShirt）</a> </ul> <ul> <li><a href="https://github.com/JuliaLang/julia/blob/master/CONTRIBUTING.md">贡献指南</a> <li><a href="https://github.com/JuliaLang/julia/issues">问题追踪器</a> <li><a href="https://github.com/JuliaLang/julia/security/policy">报告安全问题</a> <li><a href="https://github.com/issues?q=is%3Aopen+is%3Aissue+language%3AJulia+label%3A%22help+wanted%22">需要帮助的问题</a> <li><a href="https://github.com/issues?q=is%3Aopen+is%3Aissue+language%3AJulia+label%3A%22good+first+issue%22+">适宜新手做贡献的问题</a> <li><a href="https://docs.juliacn.com/latest/devdocs/reflection/">开发者文档</a> </ul> </div> <div id=footer-bottom  class=row > <div class="col-md-10 py-2"> <p>网站基于 <a href="https://franklinjl.org">Franklin.jl</a> 构建 —— 用于构建网站的纯 Julia 包。感谢 <a href="https://www.fastly.com">Fastly</a> 和 <a href="https://swarma.org/">集智俱乐部</a> 慷慨的基础设施支持。</p> <p>©2020 JuliaLang.org <a href="https://github.com/JuliaLang/www.julialang.org/graphs/contributors">英文贡献者</a>、<a href="https://github.com/JuliaCN/juliacn.github.io/graphs/contributors">中文贡献者</a>。本站内容基于 <a href="https://github.com/JuliaLang/www.julialang.org/blob/master/LICENSE.md">MIT 协议</a> 分发。 </div> <div class="col-md-2 py-2"> <span class=float-sm-right > <a class=github-button  href="https://github.com/sponsors/julialang" data-icon=octicon-heart  data-size=large  aria-label="Sponsor @julialang on GitHub">赞助 JuliaLang 组织</a> </span> </div> </div> </div> </footer> <script src="/libs/jquery/jquery.min.js"></script> <script src="/libs/bootstrap/bootstrap.min.js"></script>