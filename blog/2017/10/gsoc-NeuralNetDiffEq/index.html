<!doctype html> <html lang=en > <meta charset=utf-8 > <meta name=viewport  content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv=x-ua-compatible  content="ie=edge"> <meta name=author  content="Julia 中文社区的全体成员"> <meta name=description  content="Julia 中文社区的主页。Julia 中文社区是一个社区驱动、致力于 Julia 编程语言中文支持的开源组织。"> <meta name=keywords  content="Julia 中文, Julia 语言, Julia 中文社区, Julia 编程语言"> <meta name=robots  content="index, follow"> <meta property="og:title" content="Julia 中文社区"> <meta property="og:image" content="/assets/infra/logo_cn.png"> <meta property="og:description" content="社区驱动，致力于 Julia 编程语言中文支持的开源组织"> <link rel=stylesheet  href="/libs/bootstrap/bootstrap.min.css"> <link rel=stylesheet  href="/css/app.css"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/fonts.css"> <link href="https://fonts.googleapis.com/css?family=Roboto:400,400i,500,500i,700,700i" rel=stylesheet > <link href="https://libs.cdnjs.net/font-awesome/4.7.0/css/font-awesome.min.css" rel=stylesheet > <script async defer src="/libs/buttons.js"></script> <!-- --> <script type="application/javascript"> var doNotTrack = false; if (!doNotTrack) { window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date; ga('create', 'UA-28835595-9', 'auto'); ga('send', 'pageview'); } </script> <script async src='https://www.google-analytics.com/analytics.js'></script> <link rel=icon  href="/assets/infra/julia.ico"> <link rel=stylesheet  href="/libs/katex/katex.min.css"> <link rel=stylesheet  href="/libs/highlight/github.min.css"> <title>NeuralNetDiffEq.jl: A Neural Network solver for ODEs</title> <style> .container ul li p {margin-bottom: 0;} </style> <style> .main { font-family: Georgia; } .main pre { margin-left: auto; margin-right: auto; } .main { width: 100%; font-size: 100%; } .main code { font-size: 90%; } .main pre code { font-size: 90%; } @media (min-width: 940px) { .main { width: 800px; } .container.blog-title { width: 800px;} } </style> <div class="container py-3 py-lg-0"> <nav class="navbar navbar-expand-lg navbar-light bg-light" id=main-menu > <a class=navbar-brand  href="/"> <img src="/assets/infra/logo_cn.png" alt="JuliaLang Logo"> </a> <button class="navbar-toggler ml-auto hidden-sm-up float-xs-left" type=button  data-toggle=collapse  data-target="#navbarSupportedContent" aria-controls=navbarSupportedContent  aria-expanded=false  aria-label="Toggle navigation"> <span class=navbar-toggler-icon ></span> </button> <div class="collapse navbar-collapse" id=navbarSupportedContent > <ul class="navbar-nav mx-auto"> <li class="nav-item flex-md-fill text-md-center"> <a class=nav-link  href="/downloads/">下载</a> <li class="nav-item flex-md-fill text-md-center"> <a class=nav-link  href="https://docs.juliacn.com/">文档</a> <li class="nav-item active flex-md-fill text-md-center"> <a class=nav-link  href="https://julialang.org/blog/">博客</a> <li class="nav-item flex-md-fill text-md-center"> <a class=nav-link  href="https://discourse.juliacn.com/">社区</a> <li class="nav-item flex-md-fill text-md-center"> <a class=nav-link  href="https://learn.juliacn.com/docs/meta/how_to_learn.html">学习</a> <li class="nav-item flex-md-fill text-md-center"> <a class=nav-link  href="https://julialang.org/research/">研究</a> <li class="nav-item flex-md-fill text-md-center"> <a class=nav-link  href="https://julialang.org/jsoc/">JSoC</a> </ul> <span class=navbar-right > <a class=github-button  href="https://github.com/sponsors/julialang" data-icon=octicon-heart  data-size=large  aria-label="Sponsor @julialang on GitHub">赞助 JuliaLang 组织</a> </span> </div> </nav> </div> <br><br> <div class="container blog-title"> <h1>NeuralNetDiffEq.jl: A Neural Network solver for ODEs <a type="application/rss+xml" href="https://julialang.org/feed.xml"> <i class="fa fa-rss-square rss-icon"></i> </a> </h1> <h3> <span style="font-weight: lighter;"> 13 October 2017 </span> | <span style="font-weight: bold;"></span> <span style="font-weight: bold;">Akshay Sharma </span> </h3> </div> <a href="https://github.com/JuliaLang/www.julialang.org/blob/master/blog/2017/10/gsoc-NeuralNetDiffEq.md" title="Edit this page on GitHub" class=edit-float > </a> <div class="container main"><p>My GSoC 2017 <a href="https://summerofcode.withgoogle.com/projects/#5850956641075200">project</a> was to implement a package for Julia to solve Ordinary Differential Equations using Neural Networks. The purpose of the project was to provide an additional DE solver using Neural Networks which has parallelism in time as the key advantage over other solvers which are iterative in nature. The project was based on research paper of <a href="https://arxiv.org/pdf/physics/9705023.pdf">Lagaris et al. 1997</a> which proposed the function approximation capabilities of neural networks &#40;NNs&#41; for solving differential equations. The project was a mixture of research as well as implementation aspects and still has a few parts left to work upon. I chose to work on this project as I have interest in mathematics and machine learning and it involved concepts of both the fields. The package uses <a href="https://github.com/SciML/DifferentialEquations.jl">DifferentialEquations.jl</a> for the solver interface and <a href="https://github.com/denizyuret/Knet.jl">KNet.jl</a> for NN solver implementation.</p> <h2 id=how_to_use_neural_network_for_solving_differential_equations ><a href="#how_to_use_neural_network_for_solving_differential_equations" class=header-anchor >How to use Neural Network for solving Differential Equations?</a></h2> <p>The concept of this solver is based on the UAT &#40;Universal Approximation Theorem&#41; which says that a NN with at least one hidden layer can approximate any continuous function. The neural network is made to minimize a loss function, defined as the difference between the NN&#39;s derivative and the derivative of the differential equation, which then results in the convergence of our trial solution towards the actual &#40;analytical&#41; solution of the differential equation. To know more about UAT <a href="http://neuralnetworksanddeeplearning.com/chap4.html">click here</a>.</p> <h2 id=research_aspect_of_the_project_and_the_challenge ><a href="#research_aspect_of_the_project_and_the_challenge" class=header-anchor >Research aspect of the project and the challenge</a></h2> <p>The research paper we referred to on the topic is quite old and understanding the examples as well as explanations was quite challenging. Not much research has been done on using NNs for this purpose and thus we were not able to get much help from the research papers related to the topic. The initial task was to read and understand the mathematics behind solving differential equations. Also the computational methods used to solve differential equations on computers are quite different from the ones we use on paper so it took quite some time to get familiar with them. The structure and type of NN to be used so that the solver advantages &#40;parallelism in time&#41; are retained without compromising the performance was a research subdomain as well was a challenge.</p> <p>After implementing the solver for ODEs &#40;Ordinary Differential Equations&#41; and systems of ODEs, the difficult part was to make the NN converge for the systems of ODEs on longer time domains. As there are a lot of factors involved in neural networks, like hidden layer width, number of hidden neurons, activations, weights etc., I relied on my machine learning background as well as the help from my mentors to experiment with most of the feasible settings of NN hyper-parameters and recording the accuracy of convergence and performance of the solver. Making the NNs converge for systems of ODEs is not as easy as it seems and took up most of the time for experimentation and tuning. Predicting the system of DEs solution with larger domain is still a challenge which needs to be worked upon.</p> <h2 id=implementation_and_work ><a href="#implementation_and_work" class=header-anchor >Implementation and Work</a></h2> <p>The implementation involved integration of mathematical and machine learning aspects to build a neural net solver for ODEs. The <a href="https://github.com/SciML/DiffEqBase.jl">DiffEqBase library</a> is used as a base to extend the algorithm and solver interface while the neural network was developed using the <a href="https://github.com/denizyuret/Knet.jl">Knet.jl library</a>. The work done till now can be seen on the <a href="https://github.com/SciML/NeuralNetDiffEq.jl">NeuralNetDiffEq.jl github repository</a>, primarily in <a href="https://github.com/SciML/NeuralNetDiffEq.jl/tree/SingleNN_Approach">this branch</a>. This work involves implementing a Neural Network solver for ODEs with customized interpolation based on NN prediction.</p> <h3 id=how_does_it_work ><a href="#how_does_it_work" class=header-anchor >How does it work?</a></h3> <p>We construct a trial solution for our differential equation in terms of the NN output which should also satisfy the DE boundary conditions. We define a loss function for the neural net which is the difference between the derivative of the neural net solution with regards to its input and the true derivative defined by the ODE. This is an unusual loss function, in that in includes the gradient of the network itself. It is almost unseen elsewhere in other ML applications This loss function is minimized &#40;by equating the derivative difference to zero&#41; using the NN &#40;closer to 0 better convergence&#41; with the trial solution substituted in it in place of the original function &#40;or the solution to the DE&#41;. The neural network tunes its weights using the Adam optimization algorithm on the backpropagated gradients from that loss function.</p> <p>For parallel implementation in time we use KnetArray &#40;the array type used in <a href="https://github.com/denizyuret/Knet.jl">KNet.jl</a>&#41; which uses CPU by default but GPU usage is also supported for parallelism but requires CUDNN driver installed to access GPU hardware.</p> <h2 id=examples ><a href="#examples" class=header-anchor >Examples</a></h2> <p>Below you can find a few examples on how to use the package I&#39;ve been working on. Following are the initial imports required for the package to work.</p> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> NeuralNetDiffEq
<span class=hljs-keyword >using</span> Plots; plotly()
<span class=hljs-keyword >using</span> DiffEqBase, ParameterizedFunctions
<span class=hljs-keyword >using</span> DiffEqProblemLibrary, DiffEqDevTools
<span class=hljs-keyword >using</span> Knet</code></pre> <h3 id=ode_examples ><a href="#ode_examples" class=header-anchor >ODE Examples</a></h3> <h4 id=example_1 ><a href="#example_1" class=header-anchor >Example 1</a></h4> <pre><code class="julia hljs">linear = (t,u) -&gt; (<span class=hljs-number >1.01</span>*u)
(f::typeof(linear))(::<span class=hljs-built_in >Type</span>{<span class=hljs-built_in >Val</span>{:analytic}},t,u0) = u0*exp(<span class=hljs-number >1.01</span>*t)
prob = ODEProblem(linear,<span class=hljs-number >1</span>/<span class=hljs-number >2</span>,(<span class=hljs-number >0.0</span>,<span class=hljs-number >1.0</span>))
sol = solve(prob,nnode(<span class=hljs-number >10</span>),dt=<span class=hljs-number >1</span>/<span class=hljs-number >10</span>,iterations=<span class=hljs-number >10</span>)
plot(sol,plot_analytic=<span class=hljs-literal >true</span>)</code></pre> <p><img src="/assets/blog/2017-09-04-gsoc-NeuralNetDiffEq/plot_ode1.png" alt=Plot_ode1  /></p> <pre><code class="julia hljs">sol(<span class=hljs-number >0.232</span>)

<span class=hljs-number >1</span>-element <span class=hljs-built_in >Array</span>{<span class=hljs-built_in >Any</span>,<span class=hljs-number >1</span>}:
<span class=hljs-number >0.625818</span></code></pre> <h4 id=example_2 ><a href="#example_2" class=header-anchor >Example 2</a></h4> <pre><code class="julia hljs">f = (t,u) -&gt; (t^<span class=hljs-number >3</span> + <span class=hljs-number >2</span>*t + (t^<span class=hljs-number >2</span>)*((<span class=hljs-number >1</span>+<span class=hljs-number >3</span>*(t^<span class=hljs-number >2</span>))/(<span class=hljs-number >1</span>+t+(t^<span class=hljs-number >3</span>))) - u*(t + ((<span class=hljs-number >1</span>+<span class=hljs-number >3</span>*(t^<span class=hljs-number >2</span>))/(<span class=hljs-number >1</span>+t+t^<span class=hljs-number >3</span>))))
(::typeof(f))(::<span class=hljs-built_in >Type</span>{<span class=hljs-built_in >Val</span>{:analytic}},t,u0) =  u0*exp(-(t^<span class=hljs-number >2</span>)/<span class=hljs-number >2</span>)/(<span class=hljs-number >1</span>+t+t^<span class=hljs-number >3</span>) + t^<span class=hljs-number >2</span>
prob2 = ODEProblem(f,<span class=hljs-number >1.0</span>,(<span class=hljs-number >0.0</span>,<span class=hljs-number >1.0</span>))
sol2 = solve(prob2,nnode(<span class=hljs-number >10</span>),dt=<span class=hljs-number >0.1</span>,iterations=<span class=hljs-number >200</span>)
 plot(sol,plot_analytic=<span class=hljs-literal >true</span>)</code></pre> <p><img src="/assets/blog/2017-09-04-gsoc-NeuralNetDiffEq/plot_ode2.png" alt=Plot_ode2  /></p> <pre><code class="julia hljs">sol(<span class=hljs-number >0.47</span>)

<span class=hljs-number >1</span>-element <span class=hljs-built_in >Array</span>{<span class=hljs-built_in >Any</span>,<span class=hljs-number >1</span>}:
<span class=hljs-number >0.803109</span></code></pre> <h4 id=example_3 ><a href="#example_3" class=header-anchor >Example 3</a></h4> <pre><code class="julia hljs">f2 = (t,u) -&gt; (-u/<span class=hljs-number >5</span> + exp(-t/<span class=hljs-number >5</span>).*cos(t))
(::typeof(f2))(::<span class=hljs-built_in >Type</span>{<span class=hljs-built_in >Val</span>{:analytic}},t,u0) =  exp(-t/<span class=hljs-number >5</span>)*(u0 + sin(t))
prob3 = ODEProblem(f2,<span class=hljs-built_in >Float32</span>(<span class=hljs-number >0.0</span>),(<span class=hljs-built_in >Float32</span>(<span class=hljs-number >0.0</span>),<span class=hljs-built_in >Float32</span>(<span class=hljs-number >2.0</span>)))
sol3 = solve(prob3,nnode(<span class=hljs-number >10</span>),dt=<span class=hljs-number >0.2</span>,iterations=<span class=hljs-number >1000</span>)
 plot(sol,plot_analytic=<span class=hljs-literal >true</span>)</code></pre> <p><img src="/assets/blog/2017-09-04-gsoc-NeuralNetDiffEq/plot_ode3.png" alt=Plot_ode3  /></p> <pre><code class="julia hljs">sol3([<span class=hljs-number >0.721</span>])

  <span class=hljs-number >1</span>-element <span class=hljs-built_in >Array</span>{<span class=hljs-built_in >Any</span>,<span class=hljs-number >1</span>}:
  <span class=hljs-built_in >Any</span>[<span class=hljs-number >0.574705</span>]</code></pre> <h3 id=system_of_odes_examples ><a href="#system_of_odes_examples" class=header-anchor >System of ODEs Examples</a></h3> <h4 id=example_1_ode_2d_linear ><a href="#example_1_ode_2d_linear" class=header-anchor >Example 1 ODE 2D Linear</a></h4> <pre><code class="julia hljs">f_2dlinear = (t,u) -&gt; <span class=hljs-keyword >begin</span>
    du = <span class=hljs-built_in >Array</span>{<span class=hljs-built_in >Any</span>}(length(u))
    <span class=hljs-keyword >for</span> i <span class=hljs-keyword >in</span> <span class=hljs-number >1</span>:length(u)
    du[i] = <span class=hljs-number >1.01</span>*u[i]
  <span class=hljs-keyword >end</span>
    <span class=hljs-keyword >return</span> du
<span class=hljs-keyword >end</span>
(f::typeof(f_2dlinear))(::<span class=hljs-built_in >Type</span>{<span class=hljs-built_in >Val</span>{:analytic}},t,u0) = u0*exp.(<span class=hljs-number >1.01</span>*t)
prob_ode_2Dlinear = ODEProblem(f_2dlinear,rand(<span class=hljs-number >4</span>,<span class=hljs-number >1</span>),(<span class=hljs-number >0.0</span>,<span class=hljs-number >1.0</span>))
sol1 = solve(prob_ode_2Dlinear,nnode([<span class=hljs-number >10</span>,<span class=hljs-number >50</span>]),dt=<span class=hljs-number >0.1</span>,iterations=<span class=hljs-number >100</span>)

(:iteration,<span class=hljs-number >100</span>,:loss,<span class=hljs-number >0.004670103680503722</span>)
<span class=hljs-number >16.494870</span> seconds (<span class=hljs-number >90.08</span> M allocations: <span class=hljs-number >6.204</span> GB, <span class=hljs-number >5.82</span>% gc time)</code></pre> <pre><code class="julia hljs">plot(sol1,plot_analytic=<span class=hljs-literal >true</span>)</code></pre>
<p><img src="/assets/blog/2017-09-04-gsoc-NeuralNetDiffEq/plot_ode1.png" alt=Plot_sode1  /></p>
<h4 id=example_2_lotka_volterra ><a href="#example_2_lotka_volterra" class=header-anchor >Example 2 Lotka Volterra</a></h4>
<pre><code class="julia hljs"><span class=hljs-keyword >function</span> lotka_volterra(t,u)
  du1 = <span class=hljs-number >1.5</span> .* u[<span class=hljs-number >1</span>] - <span class=hljs-number >1.0</span> .* u[<span class=hljs-number >1</span>].*u[<span class=hljs-number >2</span>]
  du2 = -<span class=hljs-number >3</span> .* u[<span class=hljs-number >2</span>] + u[<span class=hljs-number >1</span>].*u[<span class=hljs-number >2</span>]
  [du1,du2]
<span class=hljs-keyword >end</span>

lotka_volterra (generic <span class=hljs-keyword >function</span> with <span class=hljs-number >1</span> method)</code></pre>
<pre><code class="julia hljs">prob_ode_lotkavoltera = ODEProblem(lotka_volterra,<span class=hljs-built_in >Float32</span>[<span class=hljs-number >1.0</span>,<span class=hljs-number >1.0</span>],(<span class=hljs-built_in >Float32</span>(<span class=hljs-number >0.0</span>),<span class=hljs-built_in >Float32</span>(<span class=hljs-number >1.0</span>)))
sol2 = solve(prob_ode_lotkavoltera,nnode([<span class=hljs-number >10</span>,<span class=hljs-number >50</span>]),dt=<span class=hljs-number >0.2</span>,iterations=<span class=hljs-number >1000</span>)

    (:iteration,<span class=hljs-number >100</span>,:loss,<span class=hljs-number >0.020173132003438572</span>)
    (:iteration,<span class=hljs-number >200</span>,:loss,<span class=hljs-number >0.005130137452114811</span>)
    (:iteration,<span class=hljs-number >300</span>,:loss,<span class=hljs-number >0.004812458584875589</span>)
    (:iteration,<span class=hljs-number >400</span>,:loss,<span class=hljs-number >0.010083624565714974</span>)
    (:iteration,<span class=hljs-number >500</span>,:loss,<span class=hljs-number >0.0025328170079611887</span>)
    (:iteration,<span class=hljs-number >600</span>,:loss,<span class=hljs-number >0.007685579218433846</span>)
    (:iteration,<span class=hljs-number >700</span>,:loss,<span class=hljs-number >0.005065291031504465</span>)
    (:iteration,<span class=hljs-number >800</span>,:loss,<span class=hljs-number >0.005326863832044214</span>)
    (:iteration,<span class=hljs-number >900</span>,:loss,<span class=hljs-number >0.00030436474139241827</span>)
    (:iteration,<span class=hljs-number >1000</span>,:loss,<span class=hljs-number >0.0034853904995959094</span>)
     <span class=hljs-number >22.126081</span> seconds (<span class=hljs-number >99.65</span> M allocations: <span class=hljs-number >5.923</span> GB, <span class=hljs-number >5.21</span>% gc time)</code></pre>
<pre><code class="julia hljs">plot(sol2)</code></pre>
<p><img src="/assets/blog/2017-09-04-gsoc-NeuralNetDiffEq/plot_sode2.png" alt=Plot_sode2  /></p>
<p>To show that the solver with current settings and hyper-parameters does not work for a larger domain &#40;Eg 0-10&#41; <code>lotka_volterra</code> here is a graph:</p>
<pre><code class="julia hljs">prob_ode_lotkavoltera = ODEProblem(lotka_volterra,<span class=hljs-built_in >Float32</span>[<span class=hljs-number >1.0</span>,<span class=hljs-number >1.0</span>],(<span class=hljs-built_in >Float32</span>(<span class=hljs-number >0.0</span>),<span class=hljs-built_in >Float32</span>(<span class=hljs-number >5.0</span>)))
sol3 = solve(prob_ode_lotkavoltera,nnode([<span class=hljs-number >10</span>,<span class=hljs-number >50</span>]),dt=<span class=hljs-number >0.2</span>,iterations=<span class=hljs-number >1000</span>)
plot(sol3)</code></pre>
<p><img src="/assets/blog/2017-09-04-gsoc-NeuralNetDiffEq/plot_sode3.png" alt=Plot_sode3  /></p>
<p>However, the true solution should be oscillatory, indicating that the NN did not properly converge. To see more examples and experiment results you can check out my Jupyter notebooks <a href="https://nbviewer.jupyter.org/gist/akaysh/43c9db281b0bd3224114084c44263c13">here</a>.</p>
<h2 id=future_work ><a href="#future_work" class=header-anchor >Future Work</a></h2>
<p>More of research on how to optimize the NN for speed and better convergence is required. For systems of ODEs with larger domains the current Neural Network fails to converge. An optimization algorithm can be used for one time NN hyperparameter optimization so that it can work better for systems of ODEs. We tried many approaches like biasing the cost function to prioritize earlier timepoints but this failed as well. Similar problems were found in an <a href="https://github.com/SciML/TensorFlowDiffEq.jl">alternative implementation using TensorFlow &#40;TensorFlowDiffEq.jl&#41;</a>, which suggests this may just be a problem with the solving method.</p>
<h2 id=acknowledgements ><a href="#acknowledgements" class=header-anchor >Acknowledgements</a></h2>
<p>I would really want to thank my GSoC mentors Chris Rackauckas and Lyndon White for the help they provided in understanding mathematical as well as coding parts of the project. Also I would like to thank the Julia community in general for giving me opportunity to contribute and for sponsoring my JuliaCon 2017 trip which was awesome.</p>
</div><br><br>


    
        



    
    
        


    

    <footer class="container-fluid footer-copy">
  <div class=container >
    <div class="row footrow">
      <ul>
        <li><a href="/project">关于我们</a>
        <li><a href="/about/help">寻求帮助</a>
        <li><a href="https://julialang.org/community/organizations/">特定领域的 Github 组织</a>
        <li><a href="/blog/2019/02/julia-entities/">管理者</a>
        <li><a href="/research/#publications">出版物</a>
        <li><a href="/research/#sponsors">Julia 语言赞助者</a>
        <li><a href="/research/#juliacn_sponsors">Julia 中文社区赞助者</a>
      </ul>
      <ul>
        <li><a href="/downloads/">下载</a>
        <li><a href="/downloads/">所有版本</a>
        <li><a href="https://github.com/JuliaLang/julia">源代码</a>
        <li><a href="/downloads/#current_stable_release">最新稳定版（Stable）</a>
        <li><a href="/downloads/#long_term_support_release">长期支持版本（LTS）</a>
        <li><a href="/downloads/platform/#platform_specific_instructions_for_unofficial_binaries">非官方编译版本</a>
      </ul>
      <ul>
        <li><a href="https://docs.juliacn.com/latest/">文档</a>
        <li><a href="https://docs.julialang.org/en/v1/">英文文档</a>
        <li><a href="/learning/getting-started/">初学者指南</a>
        <li><a href="https://docs.juliacn.com/latest/manual/faq/">常见问题（FAQ）</a>
        <li><a href="/learning/#books">书籍</a>
      </ul>
      <ul>
        <li><a href="/community/">社区</a>
        <li><a href="/community/#2019_julia_user_and_developer_survey">用户/开发者调查</a>
        <li><a href="/diversity/">多元化</a>
        <li><a href="/community/#official_channels">官方频道</a>
        <li><a href="/community/standards/">行为准则（CoC）</a>
        <li><a href="/community/#events">活动</a>
        <li><a href="https://shop.spreadshirt.com/numfocus/official+julia+logo?idea=5bca3ad9f93764414a5de55f">周边商店（SpreadShirt）</a>
      </ul>
      <ul>
        <li><a href="https://github.com/JuliaLang/julia/blob/master/CONTRIBUTING.md">贡献指南</a>
        <li><a href="https://github.com/JuliaLang/julia/issues">问题追踪器</a>
        <li><a href="https://github.com/JuliaLang/julia/security/policy">报告安全问题</a>
        <li><a href="https://github.com/issues?q=is%3Aopen+is%3Aissue+language%3AJulia+label%3A%22help+wanted%22">需要帮助的问题</a>
        <li><a href="https://github.com/issues?q=is%3Aopen+is%3Aissue+language%3AJulia+label%3A%22good+first+issue%22+">适宜新手做贡献的问题</a>
        <li><a href="https://docs.juliacn.com/latest/devdocs/reflection/">开发者文档</a>
      </ul>
    </div>
    <div id=footer-bottom  class=row >
      <div class="col-md-10 py-2">
        <p>网站基于 <a href="https://franklinjl.org">Franklin.jl</a> 构建 —— 用于构建网站的纯 Julia 包。感谢 <a href="https://www.fastly.com">Fastly</a> 和 <a href="https://swarma.org/">集智俱乐部</a> 慷慨的基础设施支持。</p>
        <p>©2020 JuliaLang.org <a href="https://github.com/JuliaLang/www.julialang.org/graphs/contributors">英文贡献者</a>、<a href="https://github.com/JuliaCN/juliacn.github.io/graphs/contributors">中文贡献者</a>。本站内容基于 <a href="https://github.com/JuliaLang/www.julialang.org/blob/master/LICENSE.md">MIT 协议</a> 分发。
      </div>
      <div class="col-md-2 py-2">
        <span class=float-sm-right >
          <a class=github-button  href="https://github.com/sponsors/julialang" data-icon=octicon-heart  data-size=large  aria-label="Sponsor @julialang on GitHub">赞助 JuliaLang 组织</a>
        </span>
      </div>
    </div>
  </div>
</footer>

<script src="/libs/jquery/jquery.min.js"></script>
<script src="/libs/bootstrap/bootstrap.min.js"></script>