<!doctype html> <html lang=en > <meta charset=utf-8 > <meta name=viewport  content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv=x-ua-compatible  content="ie=edge"> <meta name=author  content="Julia 中文社区的全体成员"> <meta name=description  content="Julia 中文社区的主页。Julia 中文社区是一个社区驱动、致力于 Julia 编程语言中文支持的开源组织。"> <meta name=keywords  content="Julia 中文, Julia 语言, Julia 中文社区, Julia 编程语言"> <meta name=robots  content="index, follow"> <meta property="og:title" content="Julia 中文社区"> <meta property="og:image" content="/assets/infra/logo_cn.png"> <meta property="og:description" content="社区驱动，致力于 Julia 编程语言中文支持的开源组织"> <link rel=stylesheet  href="/libs/bootstrap/bootstrap.min.css"> <link rel=stylesheet  href="/css/app.css"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/fonts.css"> <link href="https://fonts.googleapis.com/css?family=Roboto:400,400i,500,500i,700,700i" rel=stylesheet > <link href="https://libs.cdnjs.net/font-awesome/4.7.0/css/font-awesome.min.css" rel=stylesheet > <script async defer src="/libs/buttons.js"></script> <!-- --> <script type="application/javascript"> var doNotTrack = false; if (!doNotTrack) { window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date; ga('create', 'UA-28835595-9', 'auto'); ga('send', 'pageview'); } </script> <script async src='https://www.google-analytics.com/analytics.js'></script> <link rel=icon  href="/assets/infra/julia.ico"> <title>Turing Projects – Summer of Code</title> <style> .container ul li p {margin-bottom: 0;} </style> <div class="container py-3 py-lg-0"> <nav class="navbar navbar-expand-lg navbar-light bg-light" id=main-menu > <a class=navbar-brand  href="/"> <img src="/assets/infra/logo_cn.png" alt="JuliaLang Logo"> </a> <button class="navbar-toggler ml-auto hidden-sm-up float-xs-left" type=button  data-toggle=collapse  data-target="#navbarSupportedContent" aria-controls=navbarSupportedContent  aria-expanded=false  aria-label="Toggle navigation"> <span class=navbar-toggler-icon ></span> </button> <div class="collapse navbar-collapse" id=navbarSupportedContent > <ul class="navbar-nav mx-auto"> <li class="nav-item flex-md-fill text-md-center"> <a class=nav-link  href="/downloads/">下载</a> <li class="nav-item flex-md-fill text-md-center"> <a class=nav-link  href="https://docs.juliacn.com/">文档</a> <li class="nav-item flex-md-fill text-md-center"> <a class=nav-link  href="https://julialang.org/blog/">博客</a> <li class="nav-item flex-md-fill text-md-center"> <a class=nav-link  href="https://discourse.juliacn.com/">社区</a> <li class="nav-item flex-md-fill text-md-center"> <a class=nav-link  href="https://learn.juliacn.com/docs/meta/how_to_learn.html">学习</a> <li class="nav-item flex-md-fill text-md-center"> <a class=nav-link  href="https://julialang.org/research/">研究</a> <li class="nav-item active flex-md-fill text-md-center"> <a class=nav-link  href="https://julialang.org/jsoc/">JSoC</a> </ul> <span class=navbar-right > <a class=github-button  href="https://github.com/sponsors/julialang" data-icon=octicon-heart  data-size=large  aria-label="Sponsor @julialang on GitHub">赞助 JuliaLang 组织</a> </span> </div> </nav> </div> <br><br> <a href="https://github.com/JuliaLang/www.julialang.org/blob/master/jsoc/gsoc/turing.md" title="Edit this page on GitHub" class=edit-float > </a> <div class="container main"><h1 id=turing_projects_summer_of_code ><a href="#turing_projects_summer_of_code" class=header-anchor >Turing Projects – Summer of Code</a></h1> <p><a href="https://turing.ml/">Turing</a> is a universal probabilistic programming language embedded in Julia. Turing allows the user to write models in standard Julia syntax, and provide a wide range of sampling-based inference methods for solving problems across probabilistic machine learning, Bayesian statistics and data science etc. Since Turing is implemented in pure Julia code, its compiler and inference methods are amenable to hacking: new model families and inference methods can be easily added. Below is a list of ideas for potential projects, though you are welcome to propose your own to the Turing team.</p> <p>Project mentors are <a href="https://github.com/yebai">Hong Ge</a>, <a href="https://github.com/cpfiffer">Cameron Pfiffer</a>, <a href="https://github.com/trappmartin">Martin Trapp</a>, <a href="https://github.com/willtebbutt">Will Tebbutt</a>, <a href="https://github.com/mohamed82008">Mohamed Tarek</a> and <a href="https://github.com/xukai92">Kai Xu</a>.</p> <h2 id=benchmarking ><a href="#benchmarking" class=header-anchor >Benchmarking</a></h2> <p>Turing&#39;s performance has been sporadically benchmarked against various other probabilistic programming languages &#40;e.g. Turing, Stan, PyMC3, TensorFlow Prob&#41;, but a systemic approach to studying where Turing excels and where it falls short would be useful. A GSoC student would implement identical models in many PPLs and build tools to benchmark all PPLs against one another.</p> <p><strong>Recommended skills:</strong> An interest in Julia and Turing, as well as experience or desire to learn about various other PPLs. Some experience with automated tasks is useful, but not necessary at the outset.</p> <p><strong>Expected output:</strong> A suite of auto-updating benchmarks that track Turing&#39;s performance on models implemented in various languages.</p> <h2 id=nested_sampling_integration ><a href="#nested_sampling_integration" class=header-anchor >Nested sampling integration</a></h2> <p>Turing focuses on modularity in inference methods, and the development team would like to see more inference methods, particularly the popular nested sampling method. A Julia package &#40;<a href="https://github.com/mileslucas/NestedSamplers.jl">NestedSamplers.jl</a>&#41; but it is not hooked up to Turing and does not currently have a stable API. A GSoC student would either integrate that package or construct their own nested sampling method and build it into Turing.</p> <p><strong>Recommended skills:</strong> Understanding of inference methods and general probability theory. Nested sampler knowledge useful but not required.</p> <p><strong>Expected output:</strong> A nested sampler that can be used with Turing models.</p> <h2 id=automated_function_memoization_by_model_annotation ><a href="#automated_function_memoization_by_model_annotation" class=header-anchor >Automated function memoization by model annotation</a></h2> <p>Function memoization is a way to reduce costly function evaluation by caching the output when the same inputs are given. Turing&#39;s Gibbs sampler often ends up <a href="https://turing.ml/dev/docs/using-turing/performancetips#reuse-computations-in-gibbs-sampling">rerunning expensive functions</a> multiple times, and it would be a significant performance improvement to allow Turing&#39;s model compiler to automatically memoize functions where appropriate. A student working on this project would become intimately familiar with Turing&#39;s model compiler and build in various automated improvements.</p> <p><strong>Recommended skills:</strong> General programming skills, hopefully with an understanding of what makes code perform efficiently.</p> <p><strong>Expected output:</strong> Additions to the Turing compiler that automatically memoize functions where appropriate.</p> <h2 id=making_distributions_gpu_compatible ><a href="#making_distributions_gpu_compatible" class=header-anchor >Making Distributions GPU compatible</a></h2> <p>Julia&#39;s GPU tooling is generally quite good, but currently Turing is not able to reliably use GPUs while sampling because <a href="https://github.com/JuliaStats/Distributions.jl">Distributions.jl</a> is not GPU compatible. A student on this project would work with the Turing developers and the Distributions developers to allow the use of GPU parallelism where possible in Turing.</p> <p><strong>Recommended skills:</strong> GPU computing. Understanding of various statistical distributions is useful but not required.</p> <p><strong>Expected output:</strong> A set of Distributions.jl objects where <code>logpdf</code> calls can be easily run through a GPU.</p> <h2 id=gpnet_extensions ><a href="#gpnet_extensions" class=header-anchor >GPnet extensions</a></h2> <p>One of Turing&#39;s satellite packages, <a href="https://github.com/TuringLang/GPnet.jl">GPnet</a>, is designed to provide a comprehensive suite of Gaussian process tools. See <a href="https://github.com/TuringLang/GPnet.jl/issues/2">this issue</a> for potential tasks – there&#39;s a lot of interesting stuff going on with GPs, and this task in particular may have some creative freedom to it.</p> <p><strong>Recommended skills:</strong> Gaussian processes. Some Python required, as GPnet uses PyCall.</p> <p><strong>Expected output:</strong> Improved GP support. The output is variable depending on the student.</p> <h2 id=model_comparison_tools ><a href="#model_comparison_tools" class=header-anchor >Model comparison tools</a></h2> <p>Turing and its satellite packages do not currently provide a comprehensive suite of model comparison tools, a critical tool for the applied statistician. A student who worked on this project would implement various model comparison tools like <a href="https://mc-stan.org/loo/">LOO and WAIC</a>, among others.</p> <p><strong>Recommended skills:</strong> General statistics. Bayesian inference and model comparison. Some Julia programming.</p> <p><strong>Expected output:</strong> An easy-to-use set of model comparison tools that allows Turing users to effortlessly compare multiple models on a variety of metrics.</p> <h2 id=mlemap_tools ><a href="#mlemap_tools" class=header-anchor >MLE/MAP tools</a></h2> <p><a href="https://en.wikipedia.org/wiki/Maximum_likelihood_estimation">Maximum likelihood estimates</a> &#40;MLE&#41; and <a href="https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation">maximum a posteriori</a> &#40;MAP&#41; estimates can currently only be done by users through a <a href="https://turing.ml/dev/docs/using-turing/advanced#maximum-a-posteriori-estimation">clunky set of workarounds</a>. A streamlined function like <code>mle&#40;model&#41;</code> or <code>map&#40;model&#41;</code> would be very useful for many of Turing&#39;s users who want to see what the MLE or MAP estimates look like, and it may be valuable to allow for functionality that allows MCMC sampling to begin from the MLE or MAP estimates. Students working on this project will work with optimization packages such as <a href="https://github.com/JuliaNLSolvers/Optim.jl">Optim.jl</a> to make MLE and MAP estimation straightforward for Turing models.</p> <p><strong>Recommended skills:</strong> Optimization, familiarity with maximum likelihood or MAP.</p> <p><strong>Expected output:</strong> <code>map</code> and <code>mle</code> &#40;names pending&#41; functions for Turing that yield maximum likelihood and maximum a posteriori estimates of a model, and potentially statistics about the estimate such as the standard errors.</p> <h2 id=static_distributions ><a href="#static_distributions" class=header-anchor >Static distributions</a></h2> <p>Small, fixed-size vectors and matrices are fairly common in Turing models. This means that sampling in Turing can probably benefit from using statically sized vectors and matrices from StaticArrays.jl instead of normal, dynamic Julia arrays. Beside the often superior performance of small static vectors and matrices, static arrays are also automatically compatible with the GPU stack in Julia. Currently, the main obstacle to using StaticArrays.jl is that distributions in Distributions.jl are not compatible with StaticArrays. A GSoC student would adapt the multivariate and matrix-variate distributions as well as the univariate distribution with vector parameters in Distributions.jl to make a spin-off package called StaticDistributions.jl. The student would then benchmark StaticDistributions.jl against Distributions.jl and showcase an example of using StaticDistributions.jl together with CuArrays.jl and/or CUDAnative.jl for GPU-acceleration.</p> <p><strong>Recommended skills:</strong> An understanding of generated functions in Julia. Some knowledge of random number generators and probability distributions. An interest in performance optimization and micro-optimization as well as general-purpose GPU programming.</p> <p><strong>Expected output:</strong> A package StaticDistributions.jl containing implementations of non-allocating multivariate and matrix-variate distributions with vectorized logpdf support, a benchmarking of StaticDistributions.jl against Distributions.jl, and tutorials on how to use StaticDistributions together with CuArrays and the Julia GPU stack.</p> </div><br><br> <footer class="container-fluid footer-copy"> <div class=container > <div class="row footrow"> <ul> <li><a href="/project">关于我们</a> <li><a href="/about/help">寻求帮助</a> <li><a href="https://julialang.org/community/organizations/">特定领域的 Github 组织</a> <li><a href="/blog/2019/02/julia-entities/">管理者</a> <li><a href="/research/#publications">出版物</a> <li><a href="/research/#sponsors">Julia 语言赞助者</a> <li><a href="/research/#juliacn_sponsors">Julia 中文社区赞助者</a> </ul> <ul> <li><a href="/downloads/">下载</a> <li><a href="/downloads/">所有版本</a> <li><a href="https://github.com/JuliaLang/julia">源代码</a> <li><a href="/downloads/#current_stable_release">最新稳定版（Stable）</a> <li><a href="/downloads/#long_term_support_release">长期支持版本（LTS）</a> <li><a href="/downloads/platform/#platform_specific_instructions_for_unofficial_binaries">非官方编译版本</a> </ul> <ul> <li><a href="https://docs.juliacn.com/latest/">文档</a> <li><a href="https://docs.julialang.org/en/v1/">英文文档</a> <li><a href="/learning/getting-started/">初学者指南</a> <li><a href="https://docs.juliacn.com/latest/manual/faq/">常见问题（FAQ）</a> <li><a href="/learning/#books">书籍</a> </ul> <ul> <li><a href="/community/">社区</a> <li><a href="/community/#2019_julia_user_and_developer_survey">用户/开发者调查</a> <li><a href="/diversity/">多元化</a> <li><a href="/community/#official_channels">官方频道</a> <li><a href="/community/standards/">行为准则（CoC）</a> <li><a href="/community/#events">活动</a> <li><a href="https://shop.spreadshirt.com/numfocus/official+julia+logo?idea=5bca3ad9f93764414a5de55f">周边商店（SpreadShirt）</a> </ul> <ul> <li><a href="https://github.com/JuliaLang/julia/blob/master/CONTRIBUTING.md">贡献指南</a> <li><a href="https://github.com/JuliaLang/julia/issues">问题追踪器</a> <li><a href="https://github.com/JuliaLang/julia/security/policy">报告安全问题</a> <li><a href="https://github.com/issues?q=is%3Aopen+is%3Aissue+language%3AJulia+label%3A%22help+wanted%22">需要帮助的问题</a> <li><a href="https://github.com/issues?q=is%3Aopen+is%3Aissue+language%3AJulia+label%3A%22good+first+issue%22+">适宜新手做贡献的问题</a> <li><a href="https://docs.juliacn.com/latest/devdocs/reflection/">开发者文档</a> </ul> </div> <div id=footer-bottom  class=row > <div class="col-md-10 py-2"> <p>网站基于 <a href="https://franklinjl.org">Franklin.jl</a> 构建 —— 用于构建网站的纯 Julia 包。感谢 <a href="https://www.fastly.com">Fastly</a> 和 <a href="https://swarma.org/">集智俱乐部</a> 慷慨的基础设施支持。</p> <p>©2020 JuliaLang.org <a href="https://github.com/JuliaLang/www.julialang.org/graphs/contributors">英文贡献者</a>、<a href="https://github.com/JuliaCN/juliacn.github.io/graphs/contributors">中文贡献者</a>。本站内容基于 <a href="https://github.com/JuliaLang/www.julialang.org/blob/master/LICENSE.md">MIT 协议</a> 分发。 </div> <div class="col-md-2 py-2"> <span class=float-sm-right > <a class=github-button  href="https://github.com/sponsors/julialang" data-icon=octicon-heart  data-size=large  aria-label="Sponsor @julialang on GitHub">赞助 JuliaLang 组织</a> </span> </div> </div> </div> </footer> <script src="/libs/jquery/jquery.min.js"></script> <script src="/libs/bootstrap/bootstrap.min.js"></script>